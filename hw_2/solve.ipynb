{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid 1378516's current affinity list: 0-79\n",
      "pid 1378516's new affinity list: 0-12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "desired_cpu_cores = \"0-12\"\n",
    "pid = os.getpid()\n",
    "os.system(f\"taskset -p -c {desired_cpu_cores} {pid}\")\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import aim\n",
    "\n",
    "from library.dataset import TrainDataset, TestDataset, ImageDataset\n",
    "from library.model import VectorQuantizer, VQVAE, EnhancedVQVAE\n",
    "from library.trainer import AdvancedTrainer\n",
    "from library.threshold import ThresholdOptimizer\n",
    "from library.evaluator import Evaluator\n",
    "\n",
    "def run_experiment(\n",
    "    optimizer_class=torch.optim.AdamW,\n",
    "    optimizer_kwargs=None,\n",
    "    model_class=EnhancedVQVAE,\n",
    "    epochs=5,\n",
    "    fine_tune_epochs=1,\n",
    "    batch_size=512,\n",
    "    use_perceptual=True,\n",
    "    image_size=128,\n",
    "):\n",
    "    # Set up Aim run and log hyperparameters\n",
    "    run = aim.Run()\n",
    "    if optimizer_kwargs is None:\n",
    "        optimizer_kwargs = {'lr': 1e-4, 'weight_decay': 1e-5}\n",
    "    hparams = {\n",
    "        \"optimizer_class\": optimizer_class.__name__,\n",
    "        **optimizer_kwargs,\n",
    "        \"model_class\": model_class.__name__,\n",
    "        \"epochs\": epochs,\n",
    "        \"fine_tune_epochs\": fine_tune_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"use_perceptual\": use_perceptual,\n",
    "        \"image_size\": image_size,\n",
    "    }\n",
    "    run[\"hparams\"] = hparams\n",
    "\n",
    "    # Device setup\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    train_dir = \"dataset/train\"\n",
    "    proliv_dir = \"dataset/proliv\"\n",
    "    test_dir = \"dataset/test/imgs\"\n",
    "    annotation_path = \"dataset/test/test_annotation.txt\"\n",
    "\n",
    "    train_dataset = TrainDataset(train_dir, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    proliv_dataset = ImageDataset(proliv_dir, transform=transform)\n",
    "    proliv_loader = DataLoader(proliv_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Split datasets\n",
    "    normal_train, normal_val = torch.utils.data.random_split(train_dataset, [0.8, 0.2])\n",
    "    val_dataset = torch.utils.data.ConcatDataset([normal_val, proliv_dataset])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    model = model_class().to(DEVICE)\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_kwargs)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = AdvancedTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=DEVICE,\n",
    "        val_loader=val_loader,\n",
    "        use_perceptual=use_perceptual,\n",
    "        run=run\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train(epochs, fine_tune_epochs=fine_tune_epochs)\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('final_model.pth')['model_state_dict'])\n",
    "\n",
    "    # Threshold optimization\n",
    "    threshold_optimizer = ThresholdOptimizer(\n",
    "        model,\n",
    "        DataLoader(normal_val, batch_size=batch_size),\n",
    "        DataLoader(proliv_dataset, batch_size=batch_size, num_workers=0),\n",
    "        DEVICE\n",
    "    )\n",
    "    optimal_threshold = threshold_optimizer.find_optimal_threshold()\n",
    "    run.track(optimal_threshold, name='optimal_threshold')\n",
    "\n",
    "    # Evaluation\n",
    "    test_dataset = TestDataset(test_dir, annotation_path, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    evaluator = Evaluator(model, DEVICE)\n",
    "    tpr, tnr = evaluator.evaluate(test_loader, optimal_threshold)\n",
    "    train_errors = evaluator.compute_errors(DataLoader(train_dataset, batch_size=batch_size, num_workers=0))\n",
    "    threshold = evaluator.determine_threshold(train_errors, 95)\n",
    "    print(f\"Final TPR: {tpr}, Final TNR: {tnr}\")\n",
    "    run.track(threshold, name='percentile_threshold')\n",
    "    run.track(tpr, name='test_tpr')\n",
    "    run.track(tnr, name='test_tnr')\n",
    "\n",
    "    # Plot reconstructions\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     test_images, _, _ = next(iter(test_loader))\n",
    "    #     test_images = test_images[:10].to(DEVICE)\n",
    "    #     reconstructions, _ = model(test_images)\n",
    "\n",
    "    # plt.figure(figsize=(16, 4))\n",
    "    # for i in range(10):\n",
    "    #     plt.subplot(2, 10, i + 1)\n",
    "    #     img = test_images[i].cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5\n",
    "    #     plt.imshow(img)\n",
    "    #     plt.axis('off')\n",
    "    #     plt.subplot(2, 10, i + 11)\n",
    "    #     recon = reconstructions[i].cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5\n",
    "    #     plt.imshow(recon)\n",
    "    #     plt.axis('off')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return {\n",
    "        \"optimal_threshold\": optimal_threshold,\n",
    "        \"percentile_threshold\": threshold,\n",
    "        \"test_tpr\": tpr,\n",
    "        \"test_tnr\": tnr,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kazanplova/anaconda3/envs/flux_train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44551e3ddce4c839436e65baeb47909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with val loss 0.0119\n",
      "\n",
      "Epoch 1/10\n",
      "Train Loss: 0.0127 | Val Loss: 0.0119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3ef77ad6f543f39eff501ab34c45e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with val loss 0.0116\n",
      "\n",
      "Epoch 2/10\n",
      "Train Loss: 0.0096 | Val Loss: 0.0116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0223841287784c5085dc16d47aadfe21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = run_experiment(\n",
    "    optimizer_class=torch.optim.SGD,\n",
    "    optimizer_kwargs={'lr': 0.01, 'momentum': 0.9},\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    use_perceptual=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD optimizer with perceptual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiment(\n",
    "    optimizer_class=torch.optim.SGD,\n",
    "    optimizer_kwargs={'lr': 0.01, 'momentum': 0.9},\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    use_perceptual=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdamW optimizer without perceptual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kazanplova/anaconda3/envs/flux_train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243ace7cbec04525a0ac707fe26448cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved new best model with val loss 0.0122\n",
      "\n",
      "Epoch 1/5\n",
      "Train Loss: 0.0146 | Val Loss: 0.0122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df555d79a8fc45a096fdf4e30a7e887a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/5\n",
      "Train Loss: 0.0312 | Val Loss: 0.0535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bf7729108f485589c1e622294aed41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/5\n",
      "Train Loss: 0.0516 | Val Loss: 0.0561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634a9148a7644b8398d2cefde4392092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = run_experiment(\n",
    "    optimizer_class=torch.optim.AdamW,\n",
    "    optimizer_kwargs={'lr':1e-4, 'weight_decay': 1e-5},\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    use_perceptual=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdamW optimizer with perceptual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiment(\n",
    "    optimizer_class=torch.optim.AdamW,\n",
    "    optimizer_kwargs={'lr':1e-4, 'weight_decay': 1e-5},\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    use_perceptual=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flux_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
