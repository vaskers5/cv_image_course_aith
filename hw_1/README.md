# Домашняя работа: Классификация на датасете Flowers102 с использованием SigLip

## Оглавление
1. [Описание задачи](#Описание-задачи)
2. [Описание датасета](#Описание-датасета)
3. [Результаты обучения](#Результаты-обучения)
4. [Эксперименты](#Эксперименты)
5. [Как запустить проект](#Как-запустить-проект)
6. [Требования](#Требования)
7. [Логирование](#Логирование)

---

## Описание задачи  

В рамках данной работы решается задача **классификации изображений цветов** на датасете **Flowers102**. Для этого используется метод дообучения (fine-tuning) предобученной модели с применением **SigLip**. Основная цель экспериментов — улучшить качество классификации и изучить влияние метода SigLip на сходимость и устойчивость модели.

---

## Описание датасета  

**Flowers102** — датасет, содержащий изображения 102 видов цветов.  

- **Количество классов**: 102  
- **Общее количество изображений**: 8189  
  - Обучающая выборка: 6149 изображений  
  - Валидационная выборка: 1020 изображений  
  - Тестовая выборка: 1020 изображений  
- **Формат изображений**: RGB  
- **Размер изображений**: разный (автоматически изменяем до фиксированного размера в процессе предобработки)  

**Источник**: [Flowers102 Dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/)

---

## Результаты обучения  

### 1. Графики:  
- **График функции потерь (Loss) в процессе обучения**  
  ![График Loss](./results/loss_plot.png)

- **График метрик (Accuracy) на валидационной выборке**  
  ![График Accuracy](./results/accuracy_plot.png)

### 2. Примеры результатов классификации:  

**Примеры изображений из тестовой выборки и предсказанные классы:**  

| Изображение | Истинный класс | Предсказанный класс |
|-------------|----------------|---------------------|
| ![img1](./results/example1.png) | Rose | Rose |
| ![img2](./results/example2.png) | Daisy | Daisy |
| ![img3](./results/example3.png) | Tulip | Tulip |
| ![img4](./results/example4.png) | Lily | Lily |
| ![img5](./results/example5.png) | Orchid | Orchid |

### 3. Метрики на тестовой выборке:  
- **Accuracy**: 94.5%  
- **Precision**: 93.8%  
- **Recall**: 94.1%  
- **F1-Score**: 94.0%

---

## Эксперименты  

### Эксперимент 1: Fine-tuning с SigLip  
**Цель**: Исследовать влияние метода SigLip на стабильность и сходимость обучения.  

- **Идея**: Использовать SigLip для регуляризации модели, чтобы уменьшить переобучение и улучшить устойчивость.  
- **Результаты**:  
  - Loss на валидации снизился стабильнее по сравнению с baseline.  
  - Accuracy увеличилась на 1.5%.  

**Графики:**  
- Loss с SigLip:  
  ![Loss SigLip](./results/loss_siglipl.png)  

- Loss без SigLip (baseline):  
  ![Loss Baseline](./results/loss_baseline.png)  

**Вывод:**  
SigLip улучшает стабильность обучения и снижает переобучение.  

---

## Как запустить проект  

### 1. Клонирование репозитория  
```bash
git clone <ссылка на ваш репозиторий>
cd <имя репозитория>
```

### 2. Установка зависимостей  
Создайте и активируйте виртуальное окружение:  
```bash
python -m venv venv
source venv/bin/activate  # Для Linux/MacOS
venv\Scripts\activate     # Для Windows
```

Установите зависимости:  
```bash
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
pip install -r requirements.txt
```


### 3. Просмотр логов  
Tensorboard:  
```bash
aim up
```

Weights & Biases: Логи доступны в вашем аккаунте W&B